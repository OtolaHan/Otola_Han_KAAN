{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNu1/O6mkd2GUB+vuj23OcF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/OtolaHan/Otola_Han_KAAN/blob/main/weighted1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3hYkcv8U6bv9",
        "outputId": "17dc548a-4ee5-4bbf-a2dc-3a8494e6b6f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Weighted F1-score: 0.4273\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Загрузка тонального словаря LinisCrowd 2015\n",
        "tone_dict = pd.read_csv('/content/words_all_full_rating.csv', sep=';')\n",
        "\n",
        "# Функция для вычисления признаков на основе тонального словаря\n",
        "def calculate_tone_features(text):\n",
        "    tokens = text.split()\n",
        "    tone_values = [tone_dict[tone_dict['Words'] == token]['average rate'].values[0] for token in tokens if token in tone_dict['Words'].values]\n",
        "    if len(tone_values) > 0:\n",
        "        return [\n",
        "            sum(tone_values) / len(tone_values),  # X1 - среднее значений тональностей слов\n",
        "            max(tone_values),  # X2 - максимальное значение тональностей слов\n",
        "            min(tone_values),  # X3 - минимальное значение тональностей слов\n",
        "            sum(tone_values),  # X4 - суммарное значение тональностей слов\n",
        "            sum(value > 0 for value in tone_values),  # X5 - количество положительных значений тональностей слов\n",
        "            sum(value < 0 for value in tone_values)  # X6 - количество отрицательных значений тональностей слов\n",
        "        ]\n",
        "    else:\n",
        "        return [0] * 6\n",
        "\n",
        "# Функция для вычисления морфологических признаков\n",
        "def calculate_morphological_features(text):\n",
        "    # Здесь необходимо реализовать вычисление морфологических признаков (X7-X20)\n",
        "    # на основе относительной частоты основных частей речи в тексте\n",
        "    # Пример реализации опущен для краткости\n",
        "    return [0] * 14\n",
        "\n",
        "# Загрузка данных из датасетов negative и positive\n",
        "negative_data = pd.read_csv('/content/negative.csv')\n",
        "positive_data = pd.read_csv('/content/positive.csv')\n",
        "\n",
        "# Объединение данных и добавление меток классов\n",
        "data = pd.concat([negative_data, positive_data], ignore_index=True)\n",
        "data['ttype'] = data['ttype'].map({-1: -1, 1: 1})\n",
        "\n",
        "# Вычисление признаков на основе тонального словаря и морфологических признаков\n",
        "data['tone_features'] = data['ttext'].apply(calculate_tone_features)\n",
        "data['morphological_features'] = data['ttext'].apply(calculate_morphological_features)\n",
        "\n",
        "# Разделение данных на обучающую и тестовую выборки\n",
        "train_data, test_data = train_test_split(data, test_size=0.025, random_state=42)\n",
        "\n",
        "# Формирование X_train_Final, y_train_Final, X_test_Final\n",
        "X_train_Final = pd.concat([pd.DataFrame(train_data['tone_features'].tolist()), pd.DataFrame(train_data['morphological_features'].tolist())], axis=1)\n",
        "y_train_Final = train_data['ttype']\n",
        "X_test_Final = pd.concat([pd.DataFrame(test_data['tone_features'].tolist()), pd.DataFrame(test_data['morphological_features'].tolist())], axis=1)\n",
        "\n",
        "# Сохранение файлов X_train_Final, y_train_Final, X_test_Final\n",
        "X_train_Final.to_csv('X_train_Final.csv', index=False, header=True)\n",
        "y_train_Final.to_csv('y_train_Final.csv', index=False, header=True)\n",
        "X_test_Final.to_csv('X_test_Final.csv', index=False, header=True)\n",
        "\n",
        "# Обучение модели\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train_Final.values, y_train_Final.values)\n",
        "\n",
        "# Предсказание на тестовых данных\n",
        "y_pred = model.predict(X_test_Final)\n",
        "\n",
        "# Загрузить данные из файла X_test_Final.csv\n",
        "X_test = pd.read_csv('X_test_Final.csv')\n",
        "\n",
        "# Взять первые 50 строк из X_test для формирования тестового набора X_test_50\n",
        "X_test_50 = X_test.sample(n=50, random_state=42)\n",
        "\n",
        "# Сформировать предсказания для X_test_50\n",
        "y_pred = model.predict(X_test_50.values)\n",
        "\n",
        "# Сохранить предсказания в файл sentiment.csv\n",
        "pd.DataFrame(y_pred, columns=['ttype']).to_csv('sentiment.csv', index=False, header=False)\n",
        "\n",
        "# Оценка качества модели с помощью weighted F1-score\n",
        "y_test = test_data['ttype'].iloc[:50]\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "print(f\"Weighted F1-score: {f1:.4f}\")"
      ]
    }
  ]
}