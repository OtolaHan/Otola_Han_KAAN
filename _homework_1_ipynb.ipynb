{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/OtolaHan/Otola_Han_KAAN/blob/main/_homework_1_ipynb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q5l7Gkv5PxDK"
      },
      "source": [
        "# Домашнее задание №1: линейная регрессия и векторное дифференцирование (10 баллов).\n",
        "\n",
        "* Максимальное количество баллов за задания в ноутбуке - 11, но больше 10 оценка не ставится, поэтому для получения максимальной оценки можно сделать не все задания.\n",
        "\n",
        "* Некоторые задания будут по вариантам (всего 4 варианта). Чтобы выяснить свой вариант, посчитайте количество букв в своей фамилии, возьмете остаток от деления на 4 и прибавьте 1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "lSOIREnNPxDL"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JZ8sHdo2PxDL"
      },
      "source": [
        "## Многомерная линейная регрессия из sklearn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "giMrVA5IPxDM"
      },
      "source": [
        "Применим многомерную регрессию из sklearn для стандартного датасета"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TYxnS0UGPxDM",
        "outputId": "97508ba9-be66-4cfd-b212-4d52605abd85"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10000, 100) (10000,)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.datasets import make_regression\n",
        "\n",
        "X, y = make_regression(n_samples = 10000)\n",
        "print(X.shape, y.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uWMR1pM7PxDM"
      },
      "source": [
        "У нас 10000 объектов и 100 признаков. Для начала решим задачу аналитически \"из коробки\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M5mi_RlLPxDM",
        "outputId": "d8b6caad-0e76-4756-c6a9-84382cd1e359"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.4626564746359752e-25\n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "reg = LinearRegression().fit(X, y)\n",
        "print(mean_squared_error(y, reg.predict(X)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Za_5dDLcPxDM"
      },
      "source": [
        "Теперь попробуем обучить линейную регрессию методом градиентного спуска \"из коробки\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MMps5JC7PxDM",
        "outputId": "5816c1c4-20f1-4620-ca9a-ed279521fd36"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.000216200157016e-12\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-4.15324419e-08, -9.09068218e-09,  5.30635819e-09,  2.80009499e-08,\n",
              "       -1.54238360e-08,  3.04259453e-08, -1.55500767e-10, -2.61292121e-08,\n",
              "       -3.56399865e-08,  1.10783861e-08,  3.08036333e-08, -1.05724849e-08,\n",
              "        5.82770437e+01, -3.28664271e-08,  4.47430701e-08,  8.87564872e-09,\n",
              "       -1.88909737e-08,  6.11377681e-09, -1.93927162e-08, -1.53831133e-08,\n",
              "        4.12841217e-08, -8.06351149e-08,  2.01400956e-08, -1.79042304e-08,\n",
              "       -7.00038370e-08, -4.03560586e-08,  2.08298571e+01,  2.14498640e+01,\n",
              "       -2.75712732e-08, -1.40943983e-08, -3.47014403e-09, -1.44634023e-08,\n",
              "        3.12031381e-08, -2.97275900e-08, -2.29478670e-10,  6.67998340e+01,\n",
              "        1.57908891e-08, -6.43582969e-09, -4.88958735e-09,  8.69434787e-09,\n",
              "       -3.68757788e-08,  8.43913493e+01, -3.95354475e-08, -4.10191241e-08,\n",
              "       -2.00425053e-08, -1.75068143e-08,  8.32485251e-09,  3.32581688e-09,\n",
              "        5.65101053e+01, -1.16540987e-08,  1.34720595e-08,  1.95497962e-08,\n",
              "       -2.00608271e-08, -5.33409589e-08, -6.42385820e-09,  4.47872186e+00,\n",
              "       -6.16147788e-08, -2.39988794e-08,  9.55894589e-09,  2.81347321e-08,\n",
              "       -2.56432686e-08, -1.56694782e-08, -1.86317438e-08, -2.69776767e-08,\n",
              "       -5.24281100e-08, -5.79204428e-09,  3.28182884e-08,  7.74507803e+01,\n",
              "       -1.95134343e-08,  1.09686468e-08, -9.27133335e-09,  1.62911421e-08,\n",
              "        5.42792829e+01, -1.81668734e-08,  3.94624889e-08,  3.19219271e-08,\n",
              "       -3.82588746e-08,  2.70043284e-08,  1.95917310e-08,  8.76727298e+00,\n",
              "       -3.74276243e-08,  3.48118644e-08, -2.00455525e-08, -4.00221172e-08,\n",
              "       -5.15035368e-09, -9.95833073e-09, -9.04484633e-09, -4.27709552e-09,\n",
              "        8.23054081e-09,  6.76497417e-11,  5.45781920e-09, -1.27383994e-08,\n",
              "       -2.13009698e-08, -5.88484909e-09,  7.29752245e-08,  7.54006349e-09,\n",
              "        3.24106217e-09,  5.55099478e-08, -4.78213430e-09,  1.10352960e-08])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "from sklearn.linear_model import SGDRegressor\n",
        "reg = SGDRegressor(alpha=0.00000001).fit(X, y)\n",
        "print(mean_squared_error(y, reg.predict(X)))\n",
        "reg.coef_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-npJW2a1PxDM"
      },
      "source": [
        "***Задание 1 (0.5 балла).*** Объясните, чем вызвано различие двух полученных значений метрики?\n",
        "\n",
        "***Задание 2 (0.5 балла).*** Подберите гиперпараметры в методе градиентного спуска так, чтобы значение MSE было близко к значению MSE, полученному при обучении LinearRegression."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HodNiYjOPxDN"
      },
      "source": [
        "## Ваша многомерная линейная регрессия"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R88i80zOPxDN"
      },
      "source": [
        "***Задание 3 (5 баллов)***. Напишите собственную многомерную линейную регрессию, оптимизирующую MSE методом *градиентного спуска*. Для этого используйте шаблонный класс.\n",
        "\n",
        "Критерий останова: либо норма разности весов на текущей и предыдущей итерациях меньше определенного значения (первый и третий варианты), либо модуль разности функционалов качества (MSE) на текущей и предыдущей итерациях меньше определенного значения (второй и четвертый варианты). Также предлагается завершать обучение в любом случае, если было произведено слишком много итераций.\n",
        "\n",
        "***Задание 4 (2 балла)***. Добавьте l1 (первый и второй варианты) или l2 (третий и четвертый варианты) регуляризацию."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "p1NSi94BPxDN"
      },
      "outputs": [],
      "source": [
        "class LinearRegression:\n",
        "    def __init__(self, alpha=0.0001, l_ratio=0.001, tol=0.001, max_iter=1000):\n",
        "        \"\"\"\n",
        "        Для начала необходимо инициализировать параметры\n",
        "        alpha - это learning rate или шаг обучения\n",
        "        l_ratio - параметр регуляризации (в данном примере не используется)\n",
        "        tol - значение для критерия останова\n",
        "        max_iter - максимальное количество итераций обучения\n",
        "        \"\"\"\n",
        "        self.alpha = alpha\n",
        "        self.l_ratio = l_ratio\n",
        "        self.tol = tol\n",
        "        self.max_iter = max_iter\n",
        "        self.weights = None\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        \"\"\"\n",
        "        Метод для обучения линейной регрессии\n",
        "        X - матрица признаков\n",
        "        y - вектор правильных ответов\n",
        "        \"\"\"\n",
        "        # Добавляем столбец единиц для учета свободного члена (intercept)\n",
        "        X = np.c_[np.ones(X.shape[0]), X]\n",
        "        self.weights = np.zeros(X.shape[1])\n",
        "\n",
        "        for iteration in range(self.max_iter):\n",
        "            predictions = np.dot(X, self.weights)\n",
        "\n",
        "            gradient = np.dot(X.T, (predictions - y)) / len(y)\n",
        "\n",
        "            self.weights -= self.alpha * gradient\n",
        "\n",
        "            if iteration > 0:\n",
        "                if np.linalg.norm(self.weights - prev_weights) < self.tol:\n",
        "                    break\n",
        "\n",
        "            prev_weights = np.copy(self.weights)\n",
        "\n",
        "    def predict(self, X):\n",
        "        \"\"\"\n",
        "        Метод для предсказаний линейной регрессии\n",
        "        X - матрица признаков\n",
        "        \"\"\"\n",
        "        # Добавляем столбец единиц для учета свободного члена (intercept)\n",
        "        X = np.c_[np.ones(X.shape[0]), X]\n",
        "        return np.dot(X, self.weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "JeDqu9S1PxDN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09ab3aa9-ca05-4105-c1bd-ea3d81525d40"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9.434655038024892e-05\n",
            "You are amazing! Great work!\n"
          ]
        }
      ],
      "source": [
        "my_reg = LinearRegression(max_iter=1000, alpha=0.1)\n",
        "my_reg.fit(X, y)\n",
        "print(mean_squared_error(y, my_reg.predict(X)))\n",
        "assert mean_squared_error(y, my_reg.predict(X)) < 1e-3\n",
        "print('You are amazing! Great work!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wmz03XmXPxDN"
      },
      "source": [
        "***Задание 5 (1 балл)***. Обучите линейную регрессию из коробки\n",
        "\n",
        "* с l1-регуляризацией (from sklearn.linear_model import Lasso, **первый и второй вариант**) или с l2-регуляризацией (from sklearn.linear_model import Ridge, **третий и четвертый вариант**)\n",
        "* со значением параметра регуляризации **0.1 - для первого и третьего варианта, 0.01 - для второго и четвертого варианта**.\n",
        "\n",
        "Обучите вашу линейную регрессию с тем же значением параметра регуляризации и сравните результаты. Сделайте выводы."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "SGOCy9FTPxDN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb42177d-a25d-4738-9fd3-37676781ea0c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE (Ridge): 2.797983347520257e-06\n",
            "MSE (Custom): 9.434655038024892e-05\n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "\n",
        "# Создание и обучение модели Ridge с L2-регуляризацией\n",
        "ridge_model = Ridge(alpha=0.1)\n",
        "ridge_model.fit(X, y)\n",
        "ridge_mse = mean_squared_error(y, ridge_model.predict(X))\n",
        "print(f'MSE (Ridge): {ridge_mse}')\n",
        "\n",
        "my_reg = LinearRegression(alpha=0.1)\n",
        "my_reg.fit(X, y)\n",
        "\n",
        "custom_mse = mean_squared_error(y, my_reg.predict(X))\n",
        "print(f'MSE (Custom): {custom_mse}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PT8j1DniPxDN"
      },
      "source": [
        "***Задание 6* (1 балл).***\n",
        "Пусть $P, Q \\in \\mathbb{R}^{n\\times n}$. Найдите $\\nabla_Q tr(PQ)$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sNSgbj3cPxDN"
      },
      "source": [
        "***Задание 7* (1 балл).***\n",
        "Пусть $x, y \\in \\mathbb{R}^{n}, M \\in \\mathbb{R}^{n\\times n}$. Найдите $\\nabla_M x^T M y$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nxyh4a62PxDN"
      },
      "source": [
        "Решения заданий 6 и 7 можно написать на листочке и отправить в anytask вместе с заполненным ноутбуком."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}