{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "name": "weighted2.ipynb",
      "authorship_tag": "ABX9TyP+XUQDW0/aQp/Lv5IkaiN1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/OtolaHan/Otola_Han_KAAN/blob/main/weighted2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pymorphy2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kuGaOH9qPagY",
        "outputId": "4e70705d-589b-4bf1-ec1f-f0838696b6ce"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pymorphy2\n",
            "  Downloading pymorphy2-0.9.1-py3-none-any.whl (55 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.5/55.5 kB\u001b[0m \u001b[31m646.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting dawg-python>=0.7.1 (from pymorphy2)\n",
            "  Downloading DAWG_Python-0.7.2-py2.py3-none-any.whl (11 kB)\n",
            "Collecting pymorphy2-dicts-ru<3.0,>=2.4 (from pymorphy2)\n",
            "  Downloading pymorphy2_dicts_ru-2.4.417127.4579844-py2.py3-none-any.whl (8.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.2/8.2 MB\u001b[0m \u001b[31m29.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting docopt>=0.6 (from pymorphy2)\n",
            "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: docopt\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13706 sha256=25c073feca279193227f9f131cc1c17dc30cf5a10e337442b8d09027712ee7d7\n",
            "  Stored in directory: /root/.cache/pip/wheels/fc/ab/d4/5da2067ac95b36618c629a5f93f809425700506f72c9732fac\n",
            "Successfully built docopt\n",
            "Installing collected packages: pymorphy2-dicts-ru, docopt, dawg-python, pymorphy2\n",
            "Successfully installed dawg-python-0.7.2 docopt-0.6.2 pymorphy2-0.9.1 pymorphy2-dicts-ru-2.4.417127.4579844\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3hYkcv8U6bv9",
        "outputId": "032bdf37-62a3-4949-e139-cf6c786173ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Weighted F1-score: 0.4929\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import pymorphy2\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Загрузка тонального словаря LinisCrowd 2015\n",
        "tone_dict = pd.read_csv('/content/words_all_full_rating.csv', sep=';')\n",
        "\n",
        "# Функция для вычисления признаков на основе тонального словаря\n",
        "def calculate_tone_features(text):\n",
        "    tokens = text.split()\n",
        "    tone_values = [tone_dict[tone_dict['Words'] == token]['average rate'].values[0] for token in tokens if token in tone_dict['Words'].values]\n",
        "    if len(tone_values) > 0:\n",
        "        return [\n",
        "            sum(tone_values) / len(tone_values),  # X1 - среднее значений тональностей слов\n",
        "            max(tone_values),  # X2 - максимальное значение тональностей слов\n",
        "            min(tone_values),  # X3 - минимальное значение тональностей слов\n",
        "            sum(tone_values),  # X4 - суммарное значение тональностей слов\n",
        "            sum(value > 0 for value in tone_values),  # X5 - количество положительных значений тональностей слов\n",
        "            sum(value < 0 for value in tone_values)  # X6 - количество отрицательных значений тональностей слов\n",
        "        ]\n",
        "    else:\n",
        "        return [0] * 6\n",
        "\n",
        "# Инициализация анализатора\n",
        "morph = pymorphy2.MorphAnalyzer()\n",
        "\n",
        "# Функция для вычисления морфологических признаков\n",
        "def calculate_morphological_features(text):\n",
        "    tokens = text.split()\n",
        "    pos_counts = {\n",
        "        'NOUN': 0.3,\n",
        "        'ADJF': 0.2,\n",
        "        'ADJS': 0,\n",
        "        'VERB': 0,\n",
        "        'INFN': 0,\n",
        "        'GRND': 0,\n",
        "        'NUMR': 0,\n",
        "        'ADVB': 0,\n",
        "        'NPRO': 0.1,\n",
        "        'PRED': 0,\n",
        "        'PREP': 0,\n",
        "        'CONJ': 0.1,\n",
        "        'PRCL': 0,\n",
        "        'INTJ': 0\n",
        "    }\n",
        "    total_tokens = 0\n",
        "\n",
        "    for token in tokens:\n",
        "        parsed = morph.parse(token)[0]\n",
        "        pos = parsed.tag.POS\n",
        "        if pos in pos_counts:\n",
        "            pos_counts[pos] += 1\n",
        "        total_tokens += 1\n",
        "\n",
        "    features = []\n",
        "    for pos, count in pos_counts.items():\n",
        "        features.append(count / total_tokens if total_tokens > 0 else 0)\n",
        "\n",
        "    return features\n",
        "\n",
        "# Загрузка данных из датасетов negative и positive\n",
        "negative_data = pd.read_csv('/content/negative.csv')\n",
        "positive_data = pd.read_csv('/content/positive.csv')\n",
        "\n",
        "# Объединение данных и добавление меток классов\n",
        "data = pd.concat([negative_data, positive_data], ignore_index=True)\n",
        "data['ttype'] = data['ttype'].map({-1: -1, 1: 1})\n",
        "\n",
        "# Вычисление признаков на основе тонального словаря и морфологических признаков\n",
        "data['tone_features'] = data['ttext'].apply(calculate_tone_features)\n",
        "data['morphological_features'] = data['ttext'].apply(calculate_morphological_features)\n",
        "\n",
        "# Разделение данных на обучающую и тестовую выборки\n",
        "train_data, test_data = train_test_split(data, test_size=0.025, random_state=42)\n",
        "\n",
        "# Формирование X_train_Final, y_train_Final, X_test_Final\n",
        "X_train_Final = pd.concat([pd.DataFrame(train_data['tone_features'].tolist()), pd.DataFrame(train_data['morphological_features'].tolist())], axis=1)\n",
        "y_train_Final = train_data['ttype']\n",
        "X_test_Final = pd.concat([pd.DataFrame(test_data['tone_features'].tolist()), pd.DataFrame(test_data['morphological_features'].tolist())], axis=1)\n",
        "\n",
        "# Сохранение файлов X_train_Final, y_train_Final, X_test_Final\n",
        "X_train_Final.to_csv('X_train_Final.csv', index=False, header=True)\n",
        "y_train_Final.to_csv('y_train_Final.csv', index=False, header=True)\n",
        "X_test_Final.to_csv('X_test_Final.csv', index=False, header=True)\n",
        "\n",
        "# Обучение модели\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train_Final.values, y_train_Final.values)\n",
        "\n",
        "# Предсказание на тестовых данных\n",
        "y_pred = model.predict(X_test_Final)\n",
        "\n",
        "# Загрузить данные из файла X_test_Final.csv\n",
        "X_test = pd.read_csv('X_test_Final.csv')\n",
        "\n",
        "# Взять первые 50 строк из X_test для формирования тестового набора X_test_50\n",
        "X_test_50 = X_test.sample(n=50, random_state=42)\n",
        "\n",
        "# Сформировать предсказания для X_test_50\n",
        "y_pred = model.predict(X_test_50.values)\n",
        "\n",
        "# Сохранить предсказания в файл sentiment.csv\n",
        "pd.DataFrame(y_pred, columns=['ttype']).to_csv('sentiment.csv', index=False, header=False)\n",
        "\n",
        "# Оценка качества модели с помощью weighted F1-score\n",
        "y_test = test_data['ttype'].iloc[:50]\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "print(f\"Weighted F1-score: {f1:.4f}\")"
      ]
    }
  ]
}